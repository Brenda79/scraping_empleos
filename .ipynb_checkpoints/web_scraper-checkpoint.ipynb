{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from requests.exceptions import ConnectionError\n",
    "import bs4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base='https://www.sequoiacap.com/companies/'\n",
    "content={\n",
    "    \"name\": [],\n",
    "    \"url\": [],\n",
    "    \"description\": [],\n",
    "    \"milestones\": [],\n",
    "    \"team\": [],\n",
    "    \"partner\": []\n",
    "}\n",
    "delay()\n",
    "r=requests.get(base)\n",
    "soup=BeautifulSoup(r.content,'html.parser')\n",
    "\n",
    "for company in soup.find_all('div',{'class':'companies _company js-company'}):\n",
    "    \n",
    "    # parse company name\n",
    "    name=company.div.text\n",
    "    \n",
    "    #send requests to the detail company page \n",
    "    #and parse it using Beautifulsoup\n",
    "    \n",
    "    try:\n",
    "        r=requests.get(\"https://www.sequoiacap.com\" + company[\"data-url\"])\n",
    "        \n",
    "    except ConnectionError as e:\n",
    "        print(e)\n",
    "        r='No response'\n",
    "    detailed_soup=BeautifulSoup(r.content,'html.parser')\n",
    "    \n",
    "    #parse company url\n",
    "    url=detailed_soup.find_all('a',{'class':'social-link'})\n",
    "    if len(url)==0:\n",
    "        url='NA'\n",
    "    else:\n",
    "        url=detailed_soup.find('a',{'class':'social-link'})['href']\n",
    "        \n",
    "    # Parse company description\n",
    "    description=detailed_soup.find_all('div',{'class':'company-holder _body-copy -grey-dark'})\n",
    "    \n",
    "    if len(description)==0:\n",
    "        description='NA'\n",
    "    else:\n",
    "        description=detailed_soup.find('div',{'class':'company-holder _body-copy -grey-dark'}).p.text\n",
    "    \n",
    "    #parse company milestones\n",
    "    milestones=detailed_soup.find_all(text='Milestones')\n",
    "    if len(milestones) <=1:\n",
    "        milestones=\"NA\"\n",
    "    else:\n",
    "        milestones=(detailed_soup.find(text='Milestones').parent.parent.ul.text.strip().replace('\\n',';'))\n",
    "    \n",
    "    #parse company founders\n",
    "    team=detailed_soup.find_all(text='Team')\n",
    "    if len(team) <=1:\n",
    "        team=\"NA\"\n",
    "    else:\n",
    "        team=( detailed_soup.find(text='Team').parent.parent.ul.text.strip().replace('\\n',';'))\n",
    "    \n",
    "    #parse sequoia partner responsible for the company\n",
    "    partner=detailed_soup.find_all(text=re.compile('^Partners?$'))\n",
    "    if len(partner):\n",
    "        partner='NA'\n",
    "    else:\n",
    "        partner=(detailed_soup.find(text=re.compile('^Partners?$')).parent.parent.ul.text.strip().replace('\\n',';'))\n",
    "    \n",
    "    \n",
    "    #append all data belonging to this company\n",
    "    #to the content dictionary.\n",
    "    content['name'].append(name)\n",
    "    content['url'].append(url)\n",
    "    content[\"description\"].append(description)\n",
    "    content[\"milestones\"].append(milestones)\n",
    "    content[\"team\"].append(team)\n",
    "    content[\"partner\"].append(partner)\n",
    "    delay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.replace('',np.nan).fillna(value='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_null(element):\n",
    "    if type(element) != str:\n",
    "        return element.text.replace('\\n',' ').strip()\n",
    "    else:\n",
    "        return element\n",
    "    \n",
    "def delay():\n",
    "    time.sleep(random.uniform(0,2))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=requests.get('https://mx.indeed.com/browsejobs?_ga=2.52472939.2127082735.1605584059-1200163399.1577333572')\n",
    "soup_object=BeautifulSoup(response.content)\n",
    "categorias=soup_object.find_all('li',{'class':'category'})\n",
    "categ_list=[categoria.a.text for categoria in categorias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categoria in categ_list:\n",
    "    tit_list=[]\n",
    "    comp_list=[]\n",
    "    web_url=f'https://mx.indeed.com/jobs?q={categoria}&limit=50&fromage=14&start='\n",
    "    for i in range(0,500,50):\n",
    "        web_url=web_url+str(i)\n",
    "        response=requests.get(web_url)        \n",
    "        soup_object=BeautifulSoup(response.content)\n",
    "        titles=soup_object.find_all('a','jobtitle turnstileLink')\n",
    "        parents=soup_object.find_all('div',{'class':'sjcl'})\n",
    "        \n",
    "        \n",
    "        companies=[]\n",
    "        for element in parents:\n",
    "            if not element.find('span',{'class':'company'}):\n",
    "                companies.append('NA')\n",
    "            else:\n",
    "                companies.append(element.find('span',{'class':'company'}))\n",
    "                \n",
    "        tit_list=tit_list+[title.text.replace('\\n',' ').strip() for title in titles]\n",
    "        comp_list=comp_list+[handle_null(comp) for comp in companies]\n",
    "        delay()\n",
    "    \n",
    "    direct='alljobs_categorias/'\n",
    "    if not os.path.exists(direct):\n",
    "        os.makedirs(direct)\n",
    "    jobs=pd.DataFrame({'titulos':tit_list,'companias':comp_list}).drop_duplicates().reset_index(drop=True)\n",
    "    jobs.to_csv(os.path.join(direct,categoria),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
