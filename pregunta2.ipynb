{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, KeywordsOptions, EntitiesOptions, CategoriesOptions, ConceptsOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson.natural_language_understanding_v1 import SyntaxOptions,SyntaxOptionsTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson import ApiException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/emmanuel/miniconda3/envs/toughenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/emmanuel/miniconda3/envs/toughenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/emmanuel/miniconda3/envs/toughenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/emmanuel/miniconda3/envs/toughenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/emmanuel/miniconda3/envs/toughenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/emmanuel/miniconda3/envs/toughenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/emmanuel/miniconda3/envs/toughenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/emmanuel/miniconda3/envs/toughenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter api token········\n",
      "Enter url of service········\n"
     ]
    }
   ],
   "source": [
    "authenticator = IAMAuthenticator(getpass('Enter api token'))\n",
    "natural_language_understanding = NaturalLanguageUnderstandingV1(version='2020-08-01',authenticator=authenticator)\n",
    "natural_language_understanding.set_service_url(getpass('Enter url of service'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('trabajos_datascience.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "      <th>empresa</th>\n",
       "      <th>descripcion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Desarrollador de Software sin Experiencia</td>\n",
       "      <td>Minsait</td>\n",
       "      <td>Somos una de las principales empresas globales...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REDACTOR DE PRODUCCIÓN EXP. EN TV</td>\n",
       "      <td>Grupo Milenio</td>\n",
       "      <td>ESTAMOS EN BUSCA DE TU TALENTO COMO REDACTOR (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gerente de inteligencia comercial</td>\n",
       "      <td>Besins Healthcare México, S.A. de C.V.</td>\n",
       "      <td>Puesto: Gerente de inteligencia comercialOfrec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fraud Ops Analyst</td>\n",
       "      <td>Citibanamex</td>\n",
       "      <td>Publicada 13 de noviembre de 2020\\n\\nFraud Ops...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNODC- Asistente de Proyecto</td>\n",
       "      <td>UNDP</td>\n",
       "      <td>Job Description\\n\\n\\n\\n\\n\\nAgency\\n\\n\\n\\nUN Of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      titulo  \\\n",
       "0  Desarrollador de Software sin Experiencia   \n",
       "1          REDACTOR DE PRODUCCIÓN EXP. EN TV   \n",
       "2          Gerente de inteligencia comercial   \n",
       "3                          Fraud Ops Analyst   \n",
       "4               UNODC- Asistente de Proyecto   \n",
       "\n",
       "                                  empresa  \\\n",
       "0                                 Minsait   \n",
       "1                           Grupo Milenio   \n",
       "2  Besins Healthcare México, S.A. de C.V.   \n",
       "3                             Citibanamex   \n",
       "4                                    UNDP   \n",
       "\n",
       "                                         descripcion  \n",
       "0  Somos una de las principales empresas globales...  \n",
       "1  ESTAMOS EN BUSCA DE TU TALENTO COMO REDACTOR (...  \n",
       "2  Puesto: Gerente de inteligencia comercialOfrec...  \n",
       "3  Publicada 13 de noviembre de 2020\\n\\nFraud Ops...  \n",
       "4  Job Description\\n\\n\\n\\n\\n\\nAgency\\n\\n\\n\\nUN Of...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syntax_analyze(text):\n",
    "    response = natural_language_understanding.analyze(\n",
    "        text=text,\n",
    "        features=Features(syntax=SyntaxOptions(sentences=True,tokens=SyntaxOptionsTokens(part_of_speech=True))))\n",
    "    return response.get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(response,part_speech='PROPN'):\n",
    "    \n",
    "    for text in df['descripcion']:\n",
    "        propn=[]\n",
    "        for token in response['syntax']['tokens']:\n",
    "            if token['part_of_speech']==part_speech:\n",
    "                propn.append(token['text'])\n",
    "    return propn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:unsupported text language: gl\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/emmanuel/miniconda3/envs/toughenv/lib/python3.7/site-packages/ibm_cloud_sdk_core/base_service.py\", line 229, in send\n",
      "    response.status_code, error_message, http_response=response)\n",
      "ibm_cloud_sdk_core.api_exception.ApiException: Error: unsupported text language: gl, Code: 400 , X-global-transaction-id: d4a537f1-b8f7-4f92-a778-01bc8389a591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: unsupported text language: gl, Code: 400 , X-global-transaction-id: d4a537f1-b8f7-4f92-a778-01bc8389a591\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for text in df['descripcion']:\n",
    "    try:\n",
    "        result=get_tokens(syntax_analyze(text))\n",
    "    except (ApiException,ConnectionError) as e:\n",
    "        print(e)\n",
    "        result='NA'\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD LISTS\n",
    "with open('lista_tokens.dat','rb') as f:\n",
    "    results=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens']=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmanuel/miniconda3/envs/toughenv/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "save_results=np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "      <th>empresa</th>\n",
       "      <th>descripcion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Desarrollador de Software sin Experiencia</td>\n",
       "      <td>Minsait</td>\n",
       "      <td>Somos una de las principales empresas globales...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REDACTOR DE PRODUCCIÓN EXP. EN TV</td>\n",
       "      <td>Grupo Milenio</td>\n",
       "      <td>ESTAMOS EN BUSCA DE TU TALENTO COMO REDACTOR (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gerente de inteligencia comercial</td>\n",
       "      <td>Besins Healthcare México, S.A. de C.V.</td>\n",
       "      <td>Puesto: Gerente de inteligencia comercialOfrec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fraud Ops Analyst</td>\n",
       "      <td>Citibanamex</td>\n",
       "      <td>Publicada 13 de noviembre de 2020\\n\\nFraud Ops...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNODC- Asistente de Proyecto</td>\n",
       "      <td>UNDP</td>\n",
       "      <td>Job Description\\n\\n\\n\\n\\n\\nAgency\\n\\n\\n\\nUN Of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>Junior NOC Analyst</td>\n",
       "      <td>Solera</td>\n",
       "      <td>The Role\\nWe're on the hunt for a Junior NOC A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>Trade Compliance Sr. Analyst</td>\n",
       "      <td>Emerson</td>\n",
       "      <td>Trade Compliance Sr. Analyst\\n\\nRequisition ID...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>Business Program Manager</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>The IC3 Calling team is on a mission to delive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>Geodis Data Analyst</td>\n",
       "      <td>Esprezza</td>\n",
       "      <td>Descripción\\n.\\nExperiencia y Conocimientos\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>Senior Business Developer</td>\n",
       "      <td>Nubank</td>\n",
       "      <td>About Nubank\\n\\nTackling the complex banking s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>743 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        titulo  \\\n",
       "0    Desarrollador de Software sin Experiencia   \n",
       "1            REDACTOR DE PRODUCCIÓN EXP. EN TV   \n",
       "2            Gerente de inteligencia comercial   \n",
       "3                            Fraud Ops Analyst   \n",
       "4                 UNODC- Asistente de Proyecto   \n",
       "..                                         ...   \n",
       "738                         Junior NOC Analyst   \n",
       "739               Trade Compliance Sr. Analyst   \n",
       "740                   Business Program Manager   \n",
       "741                        Geodis Data Analyst   \n",
       "742                  Senior Business Developer   \n",
       "\n",
       "                                    empresa  \\\n",
       "0                                   Minsait   \n",
       "1                             Grupo Milenio   \n",
       "2    Besins Healthcare México, S.A. de C.V.   \n",
       "3                               Citibanamex   \n",
       "4                                      UNDP   \n",
       "..                                      ...   \n",
       "738                                  Solera   \n",
       "739                                 Emerson   \n",
       "740                               Microsoft   \n",
       "741                                Esprezza   \n",
       "742                                  Nubank   \n",
       "\n",
       "                                           descripcion  \n",
       "0    Somos una de las principales empresas globales...  \n",
       "1    ESTAMOS EN BUSCA DE TU TALENTO COMO REDACTOR (...  \n",
       "2    Puesto: Gerente de inteligencia comercialOfrec...  \n",
       "3    Publicada 13 de noviembre de 2020\\n\\nFraud Ops...  \n",
       "4    Job Description\\n\\n\\n\\n\\n\\nAgency\\n\\n\\n\\nUN Of...  \n",
       "..                                                 ...  \n",
       "738  The Role\\nWe're on the hunt for a Junior NOC A...  \n",
       "739  Trade Compliance Sr. Analyst\\n\\nRequisition ID...  \n",
       "740  The IC3 Calling team is on a mission to delive...  \n",
       "741  Descripción\\n.\\nExperiencia y Conocimientos\\nA...  \n",
       "742  About Nubank\\n\\nTackling the complex banking s...  \n",
       "\n",
       "[743 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "artesanal='Python, R, Java, Scala, SQL, JavaScript, C++, Hadoop, Spark, PySpark, SparkR, PostgreSQL, MySQL, \\\n",
    "Transact SQL, MongoDB, Cassandra, t-sql, Machine learning, classification, clasificación, algoritmos predictivos,\\\n",
    "clustering, regresión, deep learning, Jupyter, RStudio'.lower().split(sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "nube='IBM Cloud data and AI, AWS, Azure, GCP, Oracle, Anaconda, Watson Studio, Watson Machine Learning, Amazon SageMaker, \\\n",
    "Oracle, Cloud Service, Anaconda Enterprise, Cloudant, CouchDB, Db2 Event Store, Data Warehousing, \\\n",
    "BigML, AlteryxInc, Mozenda, OnBase, BigQuery, Snowflake, kubernetes, bluemix, saas, paas, iaas, databricks, \\\n",
    "bigquery, lambda, alibaba, elastic, elasticsearch'.lower().split(sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nube='IBM, AWS, Azure, GCP, Oracle, Anaconda, Watson, Amazon, SageMaker, \\\n",
    "Oracle, Cloud Service, Anaconda Enterprise, Cloudant, CouchDB, Db2 Event Store, Warehousing, \\\n",
    "BigML, AlteryxInc, Mozenda, OnBase, BigQuery, Snowflake, kubernetes, bluemix, saas, paas, iaas, databricks, \\\n",
    "bigquery, lambda, alibaba, elastic, elasticsearch, cloud, nube'.lower().split(sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ibm, aws, azure, gcp, oracle, anaconda, watson, amazon, sagemaker, oracle, cloud service, anaconda enterprise, cloudant, couchdb, db2 event store, warehousing, bigml, alteryxinc, mozenda, onbase, bigquery, snowflake, kubernetes, bluemix, saas, paas, iaas, databricks, bigquery, lambda, alibaba, elastic, elasticsearch, cloud, nube, "
     ]
    }
   ],
   "source": [
    "for i in nube:\n",
    "    print(i,end= ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applicar(row,categoria):\n",
    "    try:\n",
    "        return set([token.lower() for token in row]).intersection(set(categoria))\n",
    "    except TypeError as e:\n",
    "        return {}\n",
    "\n",
    "artesanales=[]\n",
    "for result in results:\n",
    "    artesanales.append(applicar(result,artesanal))\n",
    "    \n",
    "suma_art=0\n",
    "for elem in artesanales:\n",
    "    if elem:\n",
    "        suma_art+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suma_art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "nubes=[]\n",
    "for result in results:\n",
    "    nubes.append(applicar(result,nube))\n",
    "    \n",
    "suma_nube=0\n",
    "for elem in nubes:\n",
    "    if elem:\n",
    "        suma_nube+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suma_nube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=suma_nube/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.071332436069987"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=df.shape[0] #tenemos muchas observaciones, entonces es adecuado usar aprox. de limites distribucionales.\n",
    "p_estimate=suma_nube/n\n",
    "alpha=0.05 # nivel de confianza del 95%\n",
    "def conf_interval(alpha,p_estim):\n",
    "    M=norm.ppf(1-alpha/2)\n",
    "    SE=np.sqrt(p_estimate*(1-p_estimate)/n)\n",
    "    return np.array([p_estimate-M*SE,p_estimate+M*SE])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25.80622818, 32.3364367 ])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_interval(alpha,p_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suma_nube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESARROLLADOR',\n",
       " 'FULLSTACK',\n",
       " 'Home',\n",
       " 'officeProgramación',\n",
       " 'Python',\n",
       " 'CLOUD',\n",
       " 'GCP',\n",
       " 'App',\n",
       " 'Engine',\n",
       " 'Kubernetes',\n",
       " 'big',\n",
       " 'query',\n",
       " 'APIS',\n",
       " 'Google',\n",
       " 'Cloud',\n",
       " 'Platform',\n",
       " 'Java',\n",
       " 'libresPrestaciones',\n",
       " 'IMSSInfonavit',\n",
       " 'mayoresSeguro',\n",
       " 'vidaTarjeta',\n",
       " 'descuentosGastos',\n",
       " 'funerariosSeguro',\n",
       " 'Odontológico',\n",
       " 'oftalmológicoTipo',\n",
       " 'IndefinidoSalario',\n",
       " 'mesExperiencia',\n",
       " 'GOOGLE',\n",
       " 'CLOUD',\n",
       " 'PLATFORM',\n",
       " 'Python']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[569]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=70\n",
    "np.random.seed(10)\n",
    "index_sample=np.random.choice(range(0,len(results)),size=n,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([476, 358, 417, 194, 375, 569, 567, 294, 196, 179, 242, 354, 322,\n",
       "       620, 600, 494, 152, 230, 678, 627, 437,  27, 696, 195, 555,  45,\n",
       "       163, 408, 302,  94, 477, 292, 157, 217,  43, 374, 667, 220, 637,\n",
       "       617, 508, 329, 448, 559, 389, 495, 309, 202, 367, 580, 575, 345,\n",
       "        64, 299, 483, 599, 452, 584, 131, 726, 116, 143, 396, 285, 522,\n",
       "       254, 278, 222, 680, 475])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmanuel/miniconda3/envs/toughenv/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "array_results=np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suma_nube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "documents = [\"This little kitty came to play when I was eating at a restaurant.\",\n",
    "             \"Merley has the best squooshy kitten belly.\",\n",
    "             \"Google Translate app is incredible.\",\n",
    "             \"If you open 100 tab in google you get a smiley face.\",\n",
    "             \"Best cat photo I've ever taken.\",\n",
    "             \"Climbing ninja cat.\",\n",
    "             \"Impressed with google map feedback.\",\n",
    "             \"Key promoter extension for Google Chrome.\"]\n",
    "\n",
    "# documents=list(df.descripcion)\n",
    "\n",
    "# vectorizer = TfidfVectorizer(stop_words=stopwords.words('spanish'))\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 29, 28, 27, 25, 22, 20, 19, 31, 15, 14, 13, 16, 11, 10,  9,\n",
       "         6,  1, 12,  2,  3,  8, 17, 18, 24,  4, 26, 30, 32, 23, 21,  7,\n",
       "         5],\n",
       "       [32, 30,  4,  5,  7,  8, 26, 24, 23, 21, 18, 17,  3, 29, 27, 22,\n",
       "         0, 10, 20, 28,  2, 16, 15, 25,  9,  6, 14, 19, 13, 11,  1, 31,\n",
       "        12]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cluster_centers_.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " cat\n",
      " climbing\n",
      " ninja\n",
      " photo\n",
      " ve\n",
      " taken\n",
      " restaurant\n",
      " came\n",
      " play\n",
      " little\n",
      "Cluster 1:\n",
      " google\n",
      " translate\n",
      " app\n",
      " feedback\n",
      " impressed\n",
      " map\n",
      " incredible\n",
      " chrome\n",
      " extension\n",
      " promoter\n",
      "\n",
      "\n",
      "Prediction\n",
      "[1]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Prediction\")\n",
    "\n",
    "Y = vectorizer.transform([\"chrome browser to open.\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)\n",
    "\n",
    "Y = vectorizer.transform([\"My cat is hungry.\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
